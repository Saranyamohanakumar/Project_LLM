{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMU2-hX5A4GX"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import PyPDF2\n",
        "import docx\n",
        "import random\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load LLM (small one for demo)\n",
        "chatbot_model = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "\n",
        "# Store sessions for mock interview\n",
        "interview_sessions = {}\n",
        "\n",
        "# --- PDF extractor ---\n",
        "def extract_text_from_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        for page in reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text.strip()\n",
        "\n",
        "# --- DOCX extractor ---\n",
        "def extract_text_from_docx(file_path):\n",
        "    doc = docx.Document(file_path)\n",
        "    text = \"\\n\".join([para.text for para in doc.paragraphs if para.text.strip()])\n",
        "    return text.strip()\n",
        "\n",
        "# --- Universal extractor ---\n",
        "def extract_text(file_path):\n",
        "    if file_path.endswith(\".pdf\"):\n",
        "        return extract_text_from_pdf(file_path)\n",
        "    elif file_path.endswith(\".docx\"):\n",
        "        return extract_text_from_docx(file_path)\n",
        "    return \"\"\n",
        "\n",
        "# --- Generate personalized questions ---\n",
        "def generate_summary_and_questions(cv_file, jd_file):\n",
        "    if cv_file is None or jd_file is None:\n",
        "        return \"Please upload both a CV and Job Description.\", []\n",
        "\n",
        "    cv_text = extract_text(cv_file)\n",
        "    jd_text = extract_text(jd_file)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an interview coach.\n",
        "\n",
        "Candidate CV:\n",
        "{cv_text}\n",
        "\n",
        "Job Description:\n",
        "{jd_text}\n",
        "\n",
        "1. List the top 5 skills from the CV.\n",
        "2. List the top 5 key requirements from the JD.\n",
        "3. Generate 5 personalized interview questions that test the candidate on the JD requirements using the CV context.\n",
        "Format clearly:\n",
        "- CV Skills\n",
        "- JD Requirements\n",
        "- Interview Questions\n",
        "    \"\"\"\n",
        "\n",
        "    response = chatbot_model(\n",
        "        prompt,\n",
        "        max_length=600,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        temperature=0.7\n",
        "    )[0]['generated_text']\n",
        "\n",
        "    # Extract questions (simple heuristic: take last 5 numbered lines)\n",
        "    lines = response.split(\"\\n\")\n",
        "    interview_questions = [line for line in lines if line.strip().startswith((\"1\", \"2\", \"3\", \"4\", \"5\"))]\n",
        "\n",
        "    return response.replace(prompt, \"\").strip(), interview_questions[-5:]\n",
        "\n",
        "# --- Feedback generator ---\n",
        "def give_feedback(answer, question):\n",
        "    prompt = f\"As an interview coach, evaluate this answer.\\nQuestion: {question}\\nAnswer: {answer}\\nGive short feedback with strengths and weaknesses.\"\n",
        "    response = chatbot_model(\n",
        "        prompt,\n",
        "        max_length=200,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        temperature=0.7\n",
        "    )[0]['generated_text']\n",
        "    return response.replace(prompt, \"\").strip()\n",
        "\n",
        "# --- Mock interview logic ---\n",
        "def chat_with_bot(message, history):\n",
        "    session_id = id(history)\n",
        "    if session_id not in interview_sessions:\n",
        "        return \"‚ö†Ô∏è Please start the mock interview first.\"\n",
        "\n",
        "    session = interview_sessions[session_id]\n",
        "    q_index = session[\"current\"]\n",
        "    questions = session[\"questions\"]\n",
        "\n",
        "    # Evaluate user‚Äôs answer\n",
        "    last_question = questions[q_index]\n",
        "    feedback = give_feedback(message, last_question)\n",
        "\n",
        "    # Next question or finish\n",
        "    session[\"current\"] += 1\n",
        "    if session[\"current\"] < len(questions):\n",
        "        next_question = questions[session[\"current\"]]\n",
        "        return f\"üí° Feedback: {feedback}\\n\\nNext question: {next_question}\"\n",
        "    else:\n",
        "        del interview_sessions[session_id]\n",
        "        return f\"üí° Feedback: {feedback}\\n\\n‚úÖ Interview finished. Great job!\"\n",
        "\n",
        "# --- Start mock interview ---\n",
        "def start_interview(questions):\n",
        "    if not questions:\n",
        "        return \"‚ö†Ô∏è No questions available. Upload CV + JD first.\"\n",
        "    session_id = random.randint(1000, 9999)  # dummy ID\n",
        "    interview_sessions[session_id] = {\"questions\": questions, \"current\": 0}\n",
        "    return f\"üé§ Starting personalized mock interview.\\n\\nFirst question: {questions[0]}\"\n",
        "\n",
        "# --- UI with Tabs ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ü§ñ CV + JD Powered Mock Interview Coach\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        # Tab 1: Upload CV & JD\n",
        "        with gr.Tab(\"Upload & Analyze\"):\n",
        "            gr.Markdown(\"### üìÑ Upload CV & Job Description to Generate Questions\")\n",
        "            with gr.Row():\n",
        "                cv_upload = gr.File(label=\"Upload CV (PDF or DOCX)\", type=\"filepath\")\n",
        "                jd_upload = gr.File(label=\"Upload Job Description (PDF or DOCX)\", type=\"filepath\")\n",
        "\n",
        "            output = gr.Textbox(label=\"Extracted Skills, Requirements & Questions\", lines=20)\n",
        "            role_questions = gr.State([])\n",
        "\n",
        "            generate_btn = gr.Button(\"Analyze CV + JD & Generate Questions\")\n",
        "            generate_btn.click(\n",
        "                fn=generate_summary_and_questions,\n",
        "                inputs=[cv_upload, jd_upload],\n",
        "                outputs=[output, role_questions]\n",
        "            )\n",
        "\n",
        "        # Tab 2: Mock Interview\n",
        "        with gr.Tab(\"Mock Interview\"):\n",
        "            gr.Markdown(\"### üé§ Start a Personalized Mock Interview\")\n",
        "            start_btn = gr.Button(\"Start Mock Interview\")\n",
        "            start_output = gr.Textbox(label=\"Interview Status\")\n",
        "\n",
        "            start_btn.click(fn=start_interview, inputs=[role_questions], outputs=start_output)\n",
        "\n",
        "            chatbot = gr.ChatInterface(\n",
        "                fn=chat_with_bot,\n",
        "                title=\"Interview Coach\",\n",
        "                description=\"Answer the questions. Bot will give feedback and move to the next.\"\n",
        "            )\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "!pip install python-docx\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "plfOFaWjCrp8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}