{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "!pip install python-docx\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "plfOFaWjCrp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMU2-hX5A4GX"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import PyPDF2\n",
        "import docx\n",
        "import random\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load LLM (small one for demo)\n",
        "#chatbot_model = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "\n",
        "import openai\n",
        "\n",
        "def call_openai(prompt, max_tokens=500):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\":\"system\",\"content\":\"You are an interview coach.\"},\n",
        "                  {\"role\":\"user\",\"content\":prompt}],\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "\n",
        "# Store sessions for mock interview\n",
        "interview_sessions = {}\n",
        "\n",
        "# --- PDF extractor ---\n",
        "def extract_text_from_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        for page in reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text.strip()\n",
        "\n",
        "# --- DOCX extractor ---\n",
        "def extract_text_from_docx(file_path):\n",
        "    doc = docx.Document(file_path)\n",
        "    text = \"\\n\".join([para.text for para in doc.paragraphs if para.text.strip()])\n",
        "    return text.strip()\n",
        "\n",
        "# --- Universal extractor ---\n",
        "def extract_text(file_path):\n",
        "    if file_path.endswith(\".pdf\"):\n",
        "        return extract_text_from_pdf(file_path)\n",
        "    elif file_path.endswith(\".docx\"):\n",
        "        return extract_text_from_docx(file_path)\n",
        "    return \"\"\n",
        "\n",
        "# --- Generate personalized questions ---\n",
        "def generate_summary_and_questions(cv_file, jd_file):\n",
        "    if cv_file is None or jd_file is None:\n",
        "        return \"Please upload both a CV and Job Description.\", []\n",
        "\n",
        "    cv_text = extract_text(cv_file)\n",
        "    jd_text = extract_text(jd_file)\n",
        "\n",
        "    import json\n",
        "\n",
        "raw = chatbot_model(prompt, max_length=800, num_return_sequences=1)[0][\"generated_text\"]\n",
        "\n",
        "# Extract only JSON part (sometimes LLMs add extra text)\n",
        "start = raw.find(\"{\")\n",
        "end = raw.rfind(\"}\") + 1\n",
        "json_str = raw[start:end]\n",
        "\n",
        "data = json.loads(json_str)\n",
        "\n",
        "return f\"CV Skills: {data['cv_skills']}\\n\\nJD Requirements: {data['jd_requirements']}\\n\\nInterview Questions: {data['interview_questions']}\", data[\"interview_questions\"]\n",
        "\n",
        "\n",
        "    response = chatbot_model(\n",
        "        prompt,\n",
        "        max_length=600,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        temperature=0.7\n",
        "    )[0]['generated_text']\n",
        "\n",
        "    # Extract questions (simple heuristic: take last 5 numbered lines)\n",
        "    lines = response.split(\"\\n\")\n",
        "    interview_questions = [line for line in lines if line.strip().startswith((\"1\", \"2\", \"3\", \"4\", \"5\"))]\n",
        "\n",
        "    return response.replace(prompt, \"\").strip(), interview_questions[-5:]\n",
        "\n",
        "# --- Feedback generator ---\n",
        "def give_feedback(answer, question):\n",
        "    prompt = f\"\"\"\n",
        "Evaluate the candidate's answer.\n",
        "\n",
        "Question: {question}\n",
        "Answer: {answer}\n",
        "\n",
        "Return JSON:\n",
        "{{\n",
        "  \"strengths\": \"...\",\n",
        "  \"weaknesses\": \"...\",\n",
        "  \"score\": 1-5\n",
        "}}\n",
        "\"\"\"\n",
        "    raw = chatbot_model(prompt, max_length=400, num_return_sequences=1)[0][\"generated_text\"]\n",
        "    start, end = raw.find(\"{\"), raw.rfind(\"}\")+1\n",
        "    feedback = json.loads(raw[start:end])\n",
        "    return feedback\n",
        "\n",
        "\n",
        "# --- Mock interview logic ---\n",
        "def chat_with_bot(message, history):\n",
        "    session_id = id(history)\n",
        "    if session_id not in interview_sessions:\n",
        "        return \"‚ö†Ô∏è Please start the mock interview first.\"\n",
        "\n",
        "    session = interview_sessions[session_id]\n",
        "    q_index = session[\"current\"]\n",
        "    questions = session[\"questions\"]\n",
        "\n",
        "    # Evaluate user‚Äôs answer\n",
        "    last_question = questions[q_index]\n",
        "    feedback = give_feedback(message, last_question)\n",
        "\n",
        "    # Next question or finish\n",
        "    session[\"current\"] += 1\n",
        "    if session[\"current\"] < len(questions):\n",
        "        next_question = questions[session[\"current\"]]\n",
        "        return f\"üí° Feedback: {feedback}\\n\\nNext question: {next_question}\"\n",
        "    else:\n",
        "        del interview_sessions[session_id]\n",
        "        return f\"üí° Feedback: {feedback}\\n\\n‚úÖ Interview finished. Great job!\"\n",
        "\n",
        "# --- Start mock interview ---\n",
        "def start_interview(questions):\n",
        "    if not questions:\n",
        "        return \"‚ö†Ô∏è No questions available. Upload CV + JD first.\"\n",
        "    session_id = random.randint(1000, 9999)  # dummy ID\n",
        "    interview_sessions[session_id] = {\"questions\": questions, \"current\": 0}\n",
        "    return f\"üé§ Starting personalized mock interview.\\n\\nFirst question: {questions[0]}\"\n",
        "\n",
        "# --- UI with Tabs ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ü§ñ CV + JD Powered Mock Interview Coach\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        # Tab 1: Upload CV & JD\n",
        "        with gr.Tab(\"Upload & Analyze\"):\n",
        "            gr.Markdown(\"### üìÑ Upload CV & Job Description to Generate Questions\")\n",
        "            with gr.Row():\n",
        "                cv_upload = gr.File(label=\"Upload CV (PDF or DOCX)\", type=\"filepath\")\n",
        "                jd_upload = gr.File(label=\"Upload Job Description (PDF or DOCX)\", type=\"filepath\")\n",
        "\n",
        "            output = gr.Textbox(label=\"Extracted Skills, Requirements & Questions\", lines=20)\n",
        "            role_questions = gr.State([])\n",
        "\n",
        "            generate_btn = gr.Button(\"Analyze CV + JD & Generate Questions\")\n",
        "            generate_btn.click(\n",
        "                fn=generate_summary_and_questions,\n",
        "                inputs=[cv_upload, jd_upload],\n",
        "                outputs=[output, role_questions]\n",
        "            )\n",
        "\n",
        "        # Tab 2: Mock Interview\n",
        "        with gr.Tab(\"Mock Interview\"):\n",
        "            gr.Markdown(\"### üé§ Start a Personalized Mock Interview\")\n",
        "            start_btn = gr.Button(\"Start Mock Interview\")\n",
        "            start_output = gr.Textbox(label=\"Interview Status\")\n",
        "\n",
        "            start_btn.click(fn=start_interview, inputs=[role_questions], outputs=start_output)\n",
        "\n",
        "            chatbot = gr.ChatInterface(\n",
        "                fn=chat_with_bot,\n",
        "                title=\"Interview Coach\",\n",
        "                description=\"Answer the questions. Bot will give feedback and move to the next.\"\n",
        "            )\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2\n"
      ],
      "metadata": {
        "id": "ysHQLWAg00tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import PyPDF2\n",
        "import docx\n",
        "import random\n",
        "import json\n",
        "from transformers import pipeline\n",
        "\n",
        "# --- Step 1: Use a better model (Flan-T5) ---\n",
        "# (smarter and instruction-tuned than distilgpt2)\n",
        "chatbot_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n",
        "\n",
        "# Store sessions for mock interview\n",
        "interview_sessions = {}\n",
        "\n",
        "# --- PDF extractor ---\n",
        "def extract_text_from_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        for page in reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text.strip()\n",
        "\n",
        "# --- DOCX extractor ---\n",
        "def extract_text_from_docx(file_path):\n",
        "    doc = docx.Document(file_path)\n",
        "    text = \"\\n\".join([para.text for para in doc.paragraphs if para.text.strip()])\n",
        "    return text.strip()\n",
        "\n",
        "# --- Universal extractor ---\n",
        "def extract_text(file_path):\n",
        "    if file_path.endswith(\".pdf\"):\n",
        "        return extract_text_from_pdf(file_path)\n",
        "    elif file_path.endswith(\".docx\"):\n",
        "        return extract_text_from_docx(file_path)\n",
        "    return \"\"\n",
        "\n",
        "# --- Step 2: Generate structured summary + questions ---\n",
        "def generate_summary_and_questions(cv_file, jd_file):\n",
        "    if cv_file is None or jd_file is None:\n",
        "        return \"Please upload both a CV and Job Description.\", []\n",
        "\n",
        "    cv_text = extract_text(cv_file)\n",
        "    jd_text = extract_text(jd_file)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an interview coach. Analyze the following CV and Job Description.\n",
        "\n",
        "CV:\n",
        "{cv_text}\n",
        "\n",
        "Job Description:\n",
        "{jd_text}\n",
        "\n",
        "Return the result in JSON format only:\n",
        "{{\n",
        "  \"cv_skills\": [\"skill1\", \"skill2\", \"skill3\"],\n",
        "  \"jd_requirements\": [\"req1\", \"req2\", \"req3\"],\n",
        "  \"interview_questions\": [\"q1\", \"q2\", \"q3\", \"q4\", \"q5\"]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "    raw = chatbot_model(prompt, max_length=800)[0][\"generated_text\"]\n",
        "\n",
        "    # Extract JSON part\n",
        "    start, end = raw.find(\"{\"), raw.rfind(\"}\") + 1\n",
        "    if start == -1 or end == -1:\n",
        "        return \"‚ö†Ô∏è Could not parse output. Try again.\", []\n",
        "\n",
        "    try:\n",
        "        data = json.loads(raw[start:end])\n",
        "    except:\n",
        "        return \"‚ö†Ô∏è Failed to decode JSON. Try again.\", []\n",
        "\n",
        "    output_text = (\n",
        "        f\"CV Skills: {data.get('cv_skills',[])}\\n\\n\"\n",
        "        f\"JD Requirements: {data.get('jd_requirements',[])}\\n\\n\"\n",
        "        f\"Interview Questions: {data.get('interview_questions',[])}\"\n",
        "    )\n",
        "\n",
        "    return output_text, data.get(\"interview_questions\", [])\n",
        "\n",
        "# --- Step 3: Structured feedback generator ---\n",
        "def give_feedback(answer, question):\n",
        "    prompt = f\"\"\"\n",
        "Evaluate the candidate's answer.\n",
        "\n",
        "Question: {question}\n",
        "Answer: {answer}\n",
        "\n",
        "Return feedback in JSON format only:\n",
        "{{\n",
        "  \"strengths\": \"short text\",\n",
        "  \"weaknesses\": \"short text\",\n",
        "  \"score\": 1-5\n",
        "}}\n",
        "\"\"\"\n",
        "    raw = chatbot_model(prompt, max_length=400)[0][\"generated_text\"]\n",
        "    start, end = raw.find(\"{\"), raw.rfind(\"}\") + 1\n",
        "\n",
        "    if start == -1 or end == -1:\n",
        "        return {\"strengths\": \"N/A\", \"weaknesses\": \"N/A\", \"score\": 0}\n",
        "\n",
        "    try:\n",
        "        feedback = json.loads(raw[start:end])\n",
        "    except:\n",
        "        feedback = {\"strengths\": \"N/A\", \"weaknesses\": \"N/A\", \"score\": 0}\n",
        "\n",
        "    return feedback\n",
        "\n",
        "# --- Mock interview logic ---\n",
        "def chat_with_bot(message, history):\n",
        "    session_id = id(history)\n",
        "    if session_id not in interview_sessions:\n",
        "        return \"‚ö†Ô∏è Please start the mock interview first.\"\n",
        "\n",
        "    session = interview_sessions[session_id]\n",
        "    q_index = session[\"current\"]\n",
        "    questions = session[\"questions\"]\n",
        "\n",
        "    last_question = questions[q_index]\n",
        "    feedback = give_feedback(message, last_question)\n",
        "\n",
        "    feedback_text = (\n",
        "        f\"üí° Strengths: {feedback['strengths']}\\n\"\n",
        "        f\"‚ùå Weaknesses: {feedback['weaknesses']}\\n\"\n",
        "        f\"‚≠ê Score: {feedback['score']}/5\"\n",
        "    )\n",
        "\n",
        "    # Next question or finish\n",
        "    session[\"current\"] += 1\n",
        "    if session[\"current\"] < len(questions):\n",
        "        next_question = questions[session[\"current\"]]\n",
        "        progress = f\"Progress: {session['current']+1}/{len(questions)}\"\n",
        "        return f\"{feedback_text}\\n\\n{progress}\\n\\nNext question: {next_question}\"\n",
        "    else:\n",
        "        del interview_sessions[session_id]\n",
        "        return f\"{feedback_text}\\n\\n‚úÖ Interview finished. Great job!\"\n",
        "\n",
        "# --- Start mock interview ---\n",
        "def start_interview(questions):\n",
        "    if not questions:\n",
        "        return \"‚ö†Ô∏è No questions available. Upload CV + JD first.\"\n",
        "    session_id = random.randint(1000, 9999)\n",
        "    interview_sessions[session_id] = {\"questions\": questions, \"current\": 0}\n",
        "    return f\"üé§ Starting personalized mock interview.\\n\\nFirst question: {questions[0]}\"\n",
        "\n",
        "# --- UI with Tabs ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ü§ñ CV + JD Powered Mock Interview Coach (Upgraded)\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        # Tab 1: Upload CV & JD\n",
        "        with gr.Tab(\"Upload & Analyze\"):\n",
        "            gr.Markdown(\"### üìÑ Upload CV & Job Description to Generate Questions\")\n",
        "            with gr.Row():\n",
        "                cv_upload = gr.File(label=\"Upload CV (PDF or DOCX)\", type=\"filepath\")\n",
        "                jd_upload = gr.File(label=\"Upload JD (PDF or DOCX)\", type=\"filepath\")\n",
        "\n",
        "            output = gr.Textbox(label=\"Extracted Skills, Requirements & Questions\", lines=20)\n",
        "            role_questions = gr.State([])\n",
        "\n",
        "            generate_btn = gr.Button(\"Analyze CV + JD & Generate Questions\")\n",
        "            generate_btn.click(\n",
        "                fn=generate_summary_and_questions,\n",
        "                inputs=[cv_upload, jd_upload],\n",
        "                outputs=[output, role_questions]\n",
        "            )\n",
        "\n",
        "        # Tab 2: Mock Interview\n",
        "        with gr.Tab(\"Mock Interview\"):\n",
        "            gr.Markdown(\"### üé§ Start a Personalized Mock Interview\")\n",
        "            start_btn = gr.Button(\"Start Mock Interview\")\n",
        "            start_output = gr.Textbox(label=\"Interview Status\")\n",
        "\n",
        "            start_btn.click(fn=start_interview, inputs=[role_questions], outputs=start_output)\n",
        "\n",
        "            chatbot = gr.ChatInterface(\n",
        "                fn=chat_with_bot,\n",
        "                title=\"Interview Coach\",\n",
        "                description=\"Answer the questions. Bot will give feedback and move to the next.\"\n",
        "            )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "D2NQx48Y0oc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import PyPDF2\n",
        "import docx\n",
        "import random\n",
        "\n",
        "# -----------------------------\n",
        "# Choose your backend: \"huggingface\" or \"gemini\"\n",
        "# -----------------------------\n",
        "#BACKEND = \"huggingface\"  # change to \"gemini\" if you want Gemini\n",
        "BACKEND = \"gemini\"  # change to \"gemini\" if you want Gemini\n",
        "# -----------------------------\n",
        "# Load LLM\n",
        "# -----------------------------\n",
        "if BACKEND == \"huggingface\":\n",
        "    from transformers import pipeline\n",
        "    chatbot_model = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "\n",
        "    def run_model(prompt, max_length=600):\n",
        "        response = chatbot_model(\n",
        "            prompt,\n",
        "            max_length=max_length,\n",
        "            num_return_sequences=1,\n",
        "            do_sample=True,\n",
        "            temperature=0.7\n",
        "        )[0]['generated_text']\n",
        "        return response.replace(prompt, \"\").strip()\n",
        "\n",
        "elif BACKEND == \"gemini\":\n",
        "    import google.generativeai as genai\n",
        "    genai.configure(api_key=\"AIzaSyDIQRh4FyZrLU_d8WzpsxJ8BOnInIKVAmM\")  # üîë replace with your API key\n",
        "    model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "\n",
        "    def run_model(prompt, max_length=600):\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text.strip()\n",
        "\n",
        "else:\n",
        "    raise ValueError(\"Invalid BACKEND. Use 'huggingface' or 'gemini'.\")\n",
        "\n",
        "# -----------------------------\n",
        "# PDF extractor\n",
        "# -----------------------------\n",
        "def extract_text_from_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        for page in reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text.strip()\n",
        "\n",
        "# -----------------------------\n",
        "# DOCX extractor\n",
        "# -----------------------------\n",
        "def extract_text_from_docx(file_path):\n",
        "    doc = docx.Document(file_path)\n",
        "    text = \"\\n\".join([para.text for para in doc.paragraphs if para.text.strip()])\n",
        "    return text.strip()\n",
        "\n",
        "# -----------------------------\n",
        "# Universal extractor\n",
        "# -----------------------------\n",
        "def extract_text(file_path):\n",
        "    if file_path.endswith(\".pdf\"):\n",
        "        return extract_text_from_pdf(file_path)\n",
        "    elif file_path.endswith(\".docx\"):\n",
        "        return extract_text_from_docx(file_path)\n",
        "    return \"\"\n",
        "\n",
        "# -----------------------------\n",
        "# Generate personalized questions\n",
        "# -----------------------------\n",
        "def generate_summary_and_questions(cv_file, jd_file):\n",
        "    if cv_file is None or jd_file is None:\n",
        "        return \"Please upload both a CV and Job Description.\", []\n",
        "\n",
        "    cv_text = extract_text(cv_file)\n",
        "    jd_text = extract_text(jd_file)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an interview coach.\n",
        "\n",
        "Candidate CV:\n",
        "{cv_text}\n",
        "\n",
        "Job Description:\n",
        "{jd_text}\n",
        "\n",
        "1. List the top 5 skills from the CV.\n",
        "2. List the top 5 key requirements from the JD.\n",
        "3. Generate 5 personalized interview questions that test the candidate on the JD requirements using the CV context.\n",
        "Format clearly:\n",
        "- CV Skills\n",
        "- JD Requirements\n",
        "- Interview Questions\n",
        "    \"\"\"\n",
        "\n",
        "    response = run_model(prompt, max_length=600)\n",
        "\n",
        "    # Extract questions (simple heuristic: last 5 numbered lines)\n",
        "    lines = response.split(\"\\n\")\n",
        "    interview_questions = [line for line in lines if line.strip().startswith((\"1\", \"2\", \"3\", \"4\", \"5\"))]\n",
        "\n",
        "    return response, interview_questions[-5:]\n",
        "\n",
        "# -----------------------------\n",
        "# Feedback generator\n",
        "# -----------------------------\n",
        "def give_feedback(answer, question):\n",
        "    prompt = f\"As an interview coach, evaluate this answer.\\nQuestion: {question}\\nAnswer: {answer}\\nGive short feedback with strengths and weaknesses.\"\n",
        "    return run_model(prompt, max_length=200)\n",
        "\n",
        "# -----------------------------\n",
        "# Mock interview logic\n",
        "# -----------------------------\n",
        "interview_sessions = {}\n",
        "\n",
        "def chat_with_bot(message, history):\n",
        "    session_id = id(history)\n",
        "    if session_id not in interview_sessions:\n",
        "        return \"‚ö†Ô∏è Please start the mock interview first.\"\n",
        "\n",
        "    session = interview_sessions[session_id]\n",
        "    q_index = session[\"current\"]\n",
        "    questions = session[\"questions\"]\n",
        "\n",
        "    last_question = questions[q_index]\n",
        "    feedback = give_feedback(message, last_question)\n",
        "\n",
        "    session[\"current\"] += 1\n",
        "    if session[\"current\"] < len(questions):\n",
        "        next_question = questions[session[\"current\"]]\n",
        "        return f\"üí° Feedback: {feedback}\\n\\nNext question: {next_question}\"\n",
        "    else:\n",
        "        del interview_sessions[session_id]\n",
        "        return f\"üí° Feedback: {feedback}\\n\\n‚úÖ Interview finished. Great job!\"\n",
        "\n",
        "def start_interview(questions):\n",
        "    if not questions:\n",
        "        return \"‚ö†Ô∏è No questions available. Upload CV + JD first.\"\n",
        "    session_id = random.randint(1000, 9999)  # dummy ID\n",
        "    interview_sessions[session_id] = {\"questions\": questions, \"current\": 0}\n",
        "    return f\"üé§ Starting personalized mock interview.\\n\\nFirst question: {questions[0]}\"\n",
        "\n",
        "# -----------------------------\n",
        "# UI\n",
        "# -----------------------------\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ü§ñ CV + JD Powered Mock Interview Coach\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Upload & Analyze\"):\n",
        "            gr.Markdown(\"### üìÑ Upload CV & Job Description to Generate Questions\")\n",
        "            with gr.Row():\n",
        "                cv_upload = gr.File(label=\"Upload CV (PDF or DOCX)\", type=\"filepath\")\n",
        "                jd_upload = gr.File(label=\"Upload Job Description (PDF or DOCX)\", type=\"filepath\")\n",
        "\n",
        "            output = gr.Textbox(label=\"Extracted Skills, Requirements & Questions\", lines=20)\n",
        "            role_questions = gr.State([])\n",
        "\n",
        "            generate_btn = gr.Button(\"Analyze CV + JD & Generate Questions\")\n",
        "            generate_btn.click(\n",
        "                fn=generate_summary_and_questions,\n",
        "                inputs=[cv_upload, jd_upload],\n",
        "                outputs=[output, role_questions]\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"Mock Interview\"):\n",
        "            gr.Markdown(\"### üé§ Start a Personalized Mock Interview\")\n",
        "            start_btn = gr.Button(\"Start Mock Interview\")\n",
        "            start_output = gr.Textbox(label=\"Interview Status\")\n",
        "\n",
        "            start_btn.click(fn=start_interview, inputs=[role_questions], outputs=start_output)\n",
        "\n",
        "            chatbot = gr.ChatInterface(\n",
        "                fn=chat_with_bot,\n",
        "                title=\"Interview Coach\",\n",
        "                description=\"Answer the questions. Bot will give feedback and move to the next.\"\n",
        "            )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "wSlL6z3N2SLi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}