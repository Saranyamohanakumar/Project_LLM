{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx\n",
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "sJpDCMPCFmeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload the CSV file into the notebook\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "8N4wHYI7KgP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymilvus"
      ],
      "metadata": {
        "id": "wg6ytpIADyPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import PyPDF2, docx, json, random\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pymilvus import connections, Collection\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 1Ô∏è‚É£ Connect to Zilliz Cloud\n",
        "# -----------------------------\n",
        "connections.connect(\n",
        "    alias=\"default\",\n",
        "    uri=\"https://in03-feb569ec82b1b76.serverless.aws-eu-central-1.cloud.zilliz.com\",  # your URI\n",
        "    token=\"520e0e883ef97fcc4663dca8514090a2a491dd29b714711e961807fdbff8a163d82abd308cf1a8ef546698eb1759aa7054cbc295\")\n",
        "\n",
        "\n",
        "collection = Collection(\"interveiw_Knowledge\")\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
      ],
      "metadata": {
        "id": "Im0ib-nvRF5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 2Ô∏è‚É£ Load LLM (small one for demo)\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "# Load LLM (small one for demo)\n",
        "chatbot_model = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"HuggingFaceH4/zephyr-7b-beta\",\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=\"auto\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "uIirWN47np5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQC1clNxnB2H"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import PyPDF2, docx, json, random\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pymilvus import connections, Collection\n",
        "import random\n",
        "\n",
        "# Store sessions for mock interview\n",
        "interview_sessions = {}\n",
        "\n",
        "# -----------------------------\n",
        "# 3Ô∏è‚É£ File Extractors\n",
        "# -----------------------------\n",
        "\n",
        "def extract_text_from_pdf(file_obj):\n",
        "    text = \"\"\n",
        "    reader = PyPDF2.PdfReader(file_obj)\n",
        "    for page in reader.pages:\n",
        "        page_text = page.extract_text()\n",
        "        if page_text:\n",
        "            text += page_text + \"\\n\"\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def extract_text_from_docx(file_obj):\n",
        "    doc = docx.Document(file_obj)\n",
        "    return \"\\n\".join([p.text for p in doc.paragraphs if p.text.strip()])\n",
        "\n",
        "\n",
        "def extract_text(file_obj):\n",
        "    name = file_obj.name\n",
        "    if name.endswith(\".pdf\"):\n",
        "        return extract_text_from_pdf(file_obj)\n",
        "    elif name.endswith(\".docx\"):\n",
        "        return extract_text_from_docx(file_obj)\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 4Ô∏è‚É£ RAG Retrieval Function\n",
        "# -----------------------------\n",
        "def retrieve_questions_from_zilliz(cv_text, jd_text, top_k=5):\n",
        "    # If user uploads blank or short files\n",
        "    if not cv_text.strip() or not jd_text.strip():\n",
        "        return get_random_questions_from_collection(top_k)\n",
        "\n",
        "    # Create a meaningful semantic search query\n",
        "    query = f\"{jd_text[:500]} related interview questions for candidate with {cv_text[:500]}\"\n",
        "    query_vector = embedder.encode([query]).tolist()\n",
        "\n",
        "    search_params = {\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 10}}\n",
        "\n",
        "    results = collection.search(\n",
        "        data=query_vector,\n",
        "        anns_field=\"embedding\",\n",
        "        param=search_params,\n",
        "        limit=50,\n",
        "        output_fields=[\"text\"]\n",
        "    )\n",
        "\n",
        "    # Extract retrieved question texts\n",
        "    hits = [hit.entity.get(\"text\") for hit in results[0] if hit.distance > 0]\n",
        "\n",
        "    # Remove duplicates while preserving order\n",
        "    hits = list(dict.fromkeys(hits))\n",
        "\n",
        "    # Fallback if no results found\n",
        "    if not hits:\n",
        "        hits = get_random_questions_from_collection(top_k)\n",
        "\n",
        "    # Randomize subset\n",
        "    hits = random.sample(hits, min(top_k, len(hits)))\n",
        "    return hits\n",
        "\n",
        "\n",
        "def get_random_questions_from_collection(n=5):\n",
        "    \"\"\"Fetch random questions from the whole collection.\"\"\"\n",
        "    data = collection.query(expr=\"\", output_fields=[\"text\"], limit=100)\n",
        "    all_qs = [d[\"text\"] for d in data]\n",
        "    return random.sample(all_qs, min(n, len(all_qs)))\n",
        "\n",
        "# -----------------------------\n",
        "# 5Ô∏è‚É£ Generate Summary + Questions\n",
        "# -----------------------------\n",
        "def generate_summary_and_questions(cv_file, jd_file):\n",
        "    if not cv_file or not jd_file:\n",
        "        return \"‚ö†Ô∏è Please upload both a CV and Job Description.\", []\n",
        "\n",
        "    cv_text = extract_text(cv_file)\n",
        "    jd_text = extract_text(jd_file)\n",
        "\n",
        "    questions = retrieve_questions_from_zilliz(cv_text, jd_text, top_k=5)\n",
        "\n",
        "    if not questions:\n",
        "        return \"No relevant questions found. Try a different job description.\", []\n",
        "\n",
        "    summary = (\n",
        "        f\"üéØ **Top {len(questions)} relevant questions retrieved from knowledge base:**\\n\\n\"\n",
        "        + \"\\n\".join([f\"{i+1}. {q}\" for i, q in enumerate(questions)])\n",
        "    )\n",
        "    return summary, questions\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 6Ô∏è‚É£ Feedback Generator\n",
        "# -----------------------------\n",
        "def give_feedback(answer, question):\n",
        "    prompt = (\n",
        "        f\"Evaluate the following candidate answer to a technical question.\\n\\n\"\n",
        "        f\"Question: {question}\\n\"\n",
        "        f\"Candidate's Answer: {answer}\\n\\n\"\n",
        "        f\"Your response must include only:\\n\"\n",
        "        f\"1Ô∏è‚É£ Evaluation: State 'Correct', 'Partially Correct', or 'Incorrect'.\\n\"\n",
        "        f\"2Ô∏è‚É£ Correct Answer: Write the ideal answer in 1‚Äì2 short sentences.\\n\"\n",
        "        f\"3Ô∏è‚É£ Review:\\n\"\n",
        "        f\"   - ‚úÖ Strengths (1 short sentence)\\n\"\n",
        "        f\"   - ‚ö†Ô∏è Areas for improvement (1 short sentence)\\n\\n\"\n",
        "        f\"Keep your total response under 100 words. Do NOT show any examples or repeat the question.\"\n",
        "    )\n",
        "\n",
        "    response = chatbot_model(\n",
        "        prompt,\n",
        "        max_new_tokens=150,\n",
        "        do_sample=False,\n",
        "        temperature=0.3,\n",
        "        top_p=0.9\n",
        "    )[0][\"generated_text\"]\n",
        "\n",
        "    return response.replace(prompt, \"\").strip()\n",
        "\n",
        "\n",
        "\n",
        "## -----------------------------\n",
        "# 7Ô∏è‚É£ Mock Interview Logic (Final Fixed Version)\n",
        "# -----------------------------\n",
        "def start_interview(questions):\n",
        "    \"\"\"Start the interview and initialize session.\"\"\"\n",
        "    if not questions:\n",
        "        return \"‚ö†Ô∏è No questions available. Please upload CV + JD first.\", {}\n",
        "\n",
        "    session_data = {\"questions\": questions, \"current\": 0}\n",
        "    first_q = questions[0]\n",
        "    status_msg = f\"üé§ **Starting personalized mock interview!**\\n\\nüß† **First question:**\\n{first_q}\"\n",
        "    return status_msg, session_data\n",
        "\n",
        "\n",
        "def chat_with_bot(message, history, session_data):\n",
        "    \"\"\"Handle user responses and provide feedback.\"\"\"\n",
        "    if not session_data or \"questions\" not in session_data or not session_data[\"questions\"]:\n",
        "        return \"‚ö†Ô∏è Please start the mock interview first.\", session_data\n",
        "\n",
        "    q_index = session_data.get(\"current\", 0)\n",
        "    questions = session_data[\"questions\"]\n",
        "\n",
        "    current_question = questions[q_index]\n",
        "    feedback = give_feedback(message, current_question)\n",
        "\n",
        "    q_index += 1\n",
        "    if q_index < len(questions):\n",
        "        session_data[\"current\"] = q_index\n",
        "        next_q = questions[q_index]\n",
        "        progress = f\"({q_index}/{len(questions)})\"\n",
        "        reply = f\"üí¨ **Feedback:** {feedback}\\n\\n‚û°Ô∏è **Next question {progress}:** {next_q}\"\n",
        "    else:\n",
        "        reply = f\"üí¨ **Final Feedback:** {feedback}\\n\\n‚úÖ Interview finished. Great job!\"\n",
        "        session_data = {}  # reset after interview\n",
        "\n",
        "    return reply, session_data\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 8Ô∏è‚É£ Gradio Interface\n",
        "# -----------------------------\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"RAG Mock Interview Coach\") as demo:\n",
        "    gr.Markdown(\"## ü§ñ CV + JD Powered Mock Interview Coach (Now with RAG & Zilliz Cloud)\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        # Tab 1: Upload & Analyze\n",
        "        with gr.Tab(\"Upload & Analyze\"):\n",
        "            gr.Markdown(\"### üìÑ Upload your CV and Job Description to generate relevant questions.\")\n",
        "            with gr.Row():\n",
        "                cv_upload = gr.File(label=\"Upload CV (PDF or DOCX)\", type=\"filepath\")\n",
        "                jd_upload = gr.File(label=\"Upload Job Description (PDF or DOCX)\", type=\"filepath\")\n",
        "\n",
        "            output = gr.Markdown(label=\"Extracted Info & Questions\")\n",
        "            role_questions = gr.State([])\n",
        "\n",
        "            generate_btn = gr.Button(\"üîç Analyze CV + JD & Retrieve Questions\")\n",
        "            generate_btn.click(\n",
        "                fn=generate_summary_and_questions,\n",
        "                inputs=[cv_upload, jd_upload],\n",
        "                outputs=[output, role_questions]\n",
        "            )\n",
        "\n",
        "        # Tab 2: Mock Interview\n",
        "        with gr.Tab(\"Mock Interview\"):\n",
        "            gr.Markdown(\"### üé§ Start Your Personalized Mock Interview\")\n",
        "\n",
        "            # Session state to persist across chat\n",
        "            session_state = gr.State({})\n",
        "\n",
        "            start_btn = gr.Button(\"üöÄ Start Mock Interview\")\n",
        "            start_output = gr.Markdown(label=\"Interview Status\")\n",
        "\n",
        "            # Start interview properly ‚Äî split text + state\n",
        "            def start_and_show(questions):\n",
        "                message, session = start_interview(questions)\n",
        "                return message, session\n",
        "\n",
        "            start_btn.click(\n",
        "                fn=start_and_show,\n",
        "                inputs=[role_questions],\n",
        "                outputs=[start_output, session_state]\n",
        "            )\n",
        "\n",
        "            chatbot = gr.ChatInterface(\n",
        "                fn=chat_with_bot,\n",
        "                title=\"Interview Coach\",\n",
        "                description=\"üí¨ Answer the question, and get instant feedback!\",\n",
        "                additional_inputs=[session_state],\n",
        "                additional_outputs=[session_state]\n",
        "            )\n",
        "\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import PyPDF2, docx\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pymilvus import connections, Collection\n",
        "import random\n",
        "\n",
        "# Connect to Milvus and load collection as before\n",
        "connections.connect(\n",
        "    alias=\"default\",\n",
        "    uri=\"https://in03-feb569ec82b1b76.serverless.aws-eu-central-1.cloud.zilliz.com\",\n",
        "    token=\"520e0e883ef97fcc4663dca8514090a2a491dd29b714711e961807fdbff8a163d82abd308cf1a8ef546698eb1759aa7054cbc295\"\n",
        ")\n",
        "collection = Collection(\"interveiw_Knowledge\")\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def extract_text_from_pdf(file_obj):\n",
        "    text = \"\"\n",
        "    reader = PyPDF2.PdfReader(file_obj)\n",
        "    for page in reader.pages:\n",
        "        page_text = page.extract_text()\n",
        "        if page_text:\n",
        "            text += page_text + \"\\n\"\n",
        "    return text.strip()\n",
        "\n",
        "def extract_text_from_docx(file_obj):\n",
        "    doc = docx.Document(file_obj)\n",
        "    return \"\\n\".join([p.text for p in doc.paragraphs if p.text.strip()])\n",
        "\n",
        "def extract_text(file_obj):\n",
        "    name = file_obj.name\n",
        "    if name.endswith(\".pdf\"):\n",
        "        return extract_text_from_pdf(file_obj)\n",
        "    elif name.endswith(\".docx\"):\n",
        "        return extract_text_from_docx(file_obj)\n",
        "    return \"\"\n",
        "\n",
        "def retrieve_questions_from_zilliz(cv_text, jd_text, top_k=5):\n",
        "    if not cv_text.strip() or not jd_text.strip():\n",
        "        return get_random_questions_from_collection(top_k)\n",
        "    query = f\"{jd_text[:500]} related interview questions for candidate with {cv_text[:500]}\"\n",
        "    query_vector = embedder.encode([query]).tolist()\n",
        "    search_params = {\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 10}}\n",
        "    results = collection.search(\n",
        "        data=query_vector,\n",
        "        anns_field=\"embedding\",\n",
        "        param=search_params,\n",
        "        limit=50,\n",
        "        output_fields=[\"text\"]\n",
        "    )\n",
        "    hits = [hit.entity.get(\"text\") for hit in results[0] if hit.distance > 0]\n",
        "    hits = list(dict.fromkeys(hits))\n",
        "    if not hits:\n",
        "        hits = get_random_questions_from_collection(top_k)\n",
        "    hits = random.sample(hits, min(top_k, len(hits)))\n",
        "    return hits\n",
        "\n",
        "def get_random_questions_from_collection(n=5):\n",
        "    data = collection.query(expr=\"\", output_fields=[\"text\"], limit=100)\n",
        "    all_qs = [d[\"text\"] for d in data]\n",
        "    return random.sample(all_qs, min(n, len(all_qs)))\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"RAG Mock Interview Coach (Streamlit Edition)\")\n",
        "st.write(\"Upload your CV and Job Description to generate relevant interview questions.\")\n",
        "\n",
        "cv_file = st.file_uploader(\"Upload CV (PDF or DOCX)\", type=[\"pdf\", \"docx\"])\n",
        "jd_file = st.file_uploader(\"Upload Job Description (PDF or DOCX)\", type=[\"pdf\", \"docx\"])\n",
        "\n",
        "if st.button(\"Analyze CV + JD & Retrieve Questions\"):\n",
        "    if cv_file and jd_file:\n",
        "        cv_text = extract_text(cv_file)\n",
        "        jd_text = extract_text(jd_file)\n",
        "        questions = retrieve_questions_from_zilliz(cv_text, jd_text, top_k=5)\n",
        "        if questions:\n",
        "            st.markdown(\"### Top Relevant Questions\")\n",
        "            for i, q in enumerate(questions):\n",
        "                st.write(f\"{i+1}. {q}\")\n",
        "        else:\n",
        "            st.warning(\"No relevant questions found. Try a different job description.\")\n",
        "    else:\n",
        "        st.warning(\"Please upload both a CV and Job Description.\")\n"
      ],
      "metadata": {
        "id": "NcwHSzrsBh8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96479814"
      },
      "source": [
        "!pip install streamlit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building RAG"
      ],
      "metadata": {
        "id": "ugbeurCvaLqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymilvus\n"
      ],
      "metadata": {
        "id": "IyCSg1gZaHnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"in03-feb569ec82b1b76.serverless.aws-eu-central-1.cloud.zilliz.com\"\n",
        "token = \"520e0e883ef97fcc4663dca8514090a2a491dd29b714711e961807fdbff8a163d82abd308cf1a8ef546698eb1759aa7054cbc295\""
      ],
      "metadata": {
        "id": "Lf3VTu1a9arJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import connections\n",
        "\n",
        "connections.connect(\n",
        "    alias=\"default\",\n",
        "    uri=\"https://in03-feb569ec82b1b76.serverless.aws-eu-central-1.cloud.zilliz.com\",\n",
        "    token=\"520e0e883ef97fcc4663dca8514090a2a491dd29b714711e961807fdbff8a163d82abd308cf1a8ef546698eb1759aa7054cbc295\"\n",
        ")"
      ],
      "metadata": {
        "id": "fqPRBXLZ-F2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "from pymilvus import Collection, connections\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# -----------------------------\n",
        "# 2Ô∏è‚É£ Load Collection\n",
        "# -----------------------------\n",
        "collection = Collection(\"interveiw_Knowledge\")\n",
        "collection.load()  # Make sure the collection is loaded into memory[web:94]\n",
        "\n",
        "# -----------------------------\n",
        "# 3Ô∏è‚É£ Query All Data (Direct Access)\n",
        "# -----------------------------\n",
        "# Fetch up to 100 records from the collection\n",
        "data = collection.query(expr=\"\", output_fields=[\"role\", \"skill\", \"question\", \"embedding\"], limit=100)\n",
        "print(\"Sample data from collection:\")\n",
        "for item in data:\n",
        "    print(item)\n",
        "\n",
        "# -----------------------------\n",
        "# 4Ô∏è‚É£ Semantic Search (Vector Search)\n",
        "# -----------------------------\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "query_text = \"Sample semantic search query\"\n",
        "query_vector = embedder.encode([query_text]).tolist()\n",
        "\n",
        "search_params = {\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 10}}\n",
        "\n",
        "results = collection.search(\n",
        "    data=query_vector,\n",
        "    anns_field=\"embedding\",  # The name of your vector field\n",
        "    param=search_params,\n",
        "    limit=5,\n",
        "    output_fields=[\"role\", \"skill\", \"question\"]\n",
        ")\n",
        "\n",
        "print(\"Semantic search results:\")\n",
        "for hit in results[0]:\n",
        "    print(hit.entity)\n",
        "\n",
        "# -----------------------------\n",
        "# 5Ô∏è‚É£ Get All Questions (for Sampling)\n",
        "# -----------------------------\n",
        "questions_data = collection.query(expr=\"\", output_fields=[\"question\"], limit=100)\n",
        "\n",
        "# Convert each string to a dictionary\n",
        "#all_questions = [ast.literal_eval(d)[\"text\"] for d in questions_data]\n",
        "#print(all_questions)\n",
        "all_questions = [d[\"text\"] for d in questions_data if \"text\" in d]\n",
        "print(\"All questions:\", all_questions)"
      ],
      "metadata": {
        "id": "OUrUpjo5uebG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(collection.schema)\n"
      ],
      "metadata": {
        "id": "VjMbhIP2vmdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions_data = collection.query(expr=\"\", output_fields=[\"text\"], limit=100)\n",
        "print(questions_data)\n"
      ],
      "metadata": {
        "id": "_befs0PawK4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Quantitative Results (Evaluation Metrics)"
      ],
      "metadata": {
        "id": "ePHWc5mK0zyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Accuracy / Correctness"
      ],
      "metadata": {
        "id": "JeBRHj1804El"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "ref_answer = \"An INNER JOIN returns only rows with matching values in both tables.\"\n",
        "gen_answer = \"INNER JOIN gives rows where both tables have matching data.\"\n",
        "\n",
        "emb_ref = model.encode(ref_answer, convert_to_tensor=True)\n",
        "emb_gen = model.encode(gen_answer, convert_to_tensor=True)\n",
        "\n",
        "similarity = util.cos_sim(emb_ref, emb_gen)\n",
        "print(f\"Semantic Similarity: {similarity.item():.3f}\")\n"
      ],
      "metadata": {
        "id": "WzlZ7mZD0zcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Interpretation:\n",
        "If similarity > 0.8 ‚Üí Good answer\n",
        "0.6‚Äì0.8 ‚Üí Partial\n",
        "<0.6 ‚Üí Poor or irrelevant"
      ],
      "metadata": {
        "id": "yj3OZ5Gh0-z0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Precision / Recall / F1 (if you classify responses)"
      ],
      "metadata": {
        "id": "dy3WvJIY0_im"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = [\"correct\", \"correct\", \"incorrect\", \"partial\"]\n",
        "y_pred = [\"correct\", \"partial\", \"incorrect\", \"correct\"]\n",
        "\n",
        "print(classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "id": "aG0Stk201BW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) BLEU or ROUGE (text similarity)"
      ],
      "metadata": {
        "id": "-T0uW5l01GLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "reference = [\"An INNER JOIN returns rows with matching values in both tables\"]\n",
        "candidate = \"INNER JOIN gives rows where both tables have matching data\"\n",
        "\n",
        "# Tokenize correctly\n",
        "reference = [ref.split() for ref in reference]   # List of tokenized reference sentences\n",
        "candidate = candidate.split()                    # Tokenized candidate\n",
        "\n",
        "bleu_score = sentence_bleu(reference, candidate)\n",
        "print(f\"BLEU Score: {bleu_score:.3f}\")\n"
      ],
      "metadata": {
        "id": "jwN2WWR51XAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ BLEU closer to 1 means closer to the reference answer."
      ],
      "metadata": {
        "id": "DhGdKh_w1xrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Latency (Response Time)"
      ],
      "metadata": {
        "id": "o_vfRDve1yRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "# Call your RAG answer function here\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Response time: {end - start:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "EE_sCaXR10Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load embedding model for semantic similarity\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "smooth = SmoothingFunction().method1\n",
        "\n",
        "def evaluate_response(reference_answer, model_answer):\n",
        "    # BLEU (with smoothing)\n",
        "    reference = [reference_answer.split()]\n",
        "    candidate = model_answer.split()\n",
        "    bleu = sentence_bleu(reference, candidate, smoothing_function=smooth)\n",
        "\n",
        "    # Semantic similarity\n",
        "    emb1 = model.encode(reference_answer, convert_to_tensor=True)\n",
        "    emb2 = model.encode(model_answer, convert_to_tensor=True)\n",
        "    similarity = util.pytorch_cos_sim(emb1, emb2).item()\n",
        "\n",
        "    return bleu, similarity\n",
        "\n",
        "\n",
        "def evaluate_system(data):\n",
        "    \"\"\"\n",
        "    data: list of dicts with keys:\n",
        "      'question', 'reference_answer', 'model_answer', 'response_time'\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for item in data:\n",
        "        bleu, sim = evaluate_response(item['reference_answer'], item['model_answer'])\n",
        "        results.append({\n",
        "            'Question': item['question'],\n",
        "            'BLEU': bleu,\n",
        "            'Semantic_Similarity': sim,\n",
        "            'Response_Time': item['response_time']\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    print(\"\\n--- Summary ---\")\n",
        "    print(df.describe())\n",
        "    df.to_csv(\"evaluation_results.csv\", index=False)\n",
        "    print(\"\\n‚úÖ Results saved to evaluation_results.csv\")\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "baLeZRPB3lZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"evaluation_results.csv\")\n"
      ],
      "metadata": {
        "id": "nlFhmdJE4o7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir())\n"
      ],
      "metadata": {
        "id": "eiJMs2un43KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from evaluate_results import evaluate_response # This import is not needed as the function is defined in this notebook\n",
        "import time\n",
        "\n",
        "# Example flow inside your Gradio callback:\n",
        "start = time.time()\n",
        "# generated_answer = model_pipeline(question)   # your Zephyr-7B response # This variable is not defined\n",
        "end = time.time()\n",
        "\n",
        "response_time = end - start\n",
        "\n",
        "# Compare with your reference answer (ground truth)\n",
        "# bleu, semantic_sim = evaluate_response(reference_answer, generated_answer) # reference_answer and generated_answer are not defined\n",
        "\n",
        "# print(f\"BLEU: {bleu:.3f}, Semantic Similarity: {semantic_sim:.3f}, Time: {response_time:.2f}s\")\n",
        "print(f\"Response time: {response_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "J1RgFCSG3yx8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}